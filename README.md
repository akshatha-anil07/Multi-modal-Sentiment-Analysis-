Multi-modal Sentiment Analysis 

## Overview

This project integrates the BLIP model for image captioning with a sentiment analysis model to perform multi-modal sentiment analysis. The system is designed to analyze social media posts that include both images and text, generating captions for images and evaluating the sentiment of both the captions and accompanying text. The overall sentiment score provides a comprehensive view of the sentiment expressed in the content.

## Instructions to Run the Project

### Prerequisites

- Python (v3.10+ recommended)
- Poetry (A Python packaging and dependency management tool)
- HuggingFaceAPI Token

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-repo/blip-integrations.git
   cd blip-integrations/src

2.  Create and Configure .env File

Create a .env file and add your HuggingFaceAPI Token:
     ````bash
     nano .env
3. 

